# ü§ñ SEMEADA

## O que √© o projeto?
O projeto, desenvolvido pela [ADA](http://adaec.icmc.usp.br/sobre-nos/) em parceria com o [SEMEAR](https://semear.eesc.usp.br/), se trata de um rob√¥ de mesa capaz de captar comandos de fala e interpret√°-los, por meio de **processamento de linguagem natural**, para realizar a√ß√µes. At√© o momento, o rob√¥ √© capaz de obedecer aos seguintes comandos:
* Dan√ßar
* Acordar
* Dormir
* Girar
* Levantar os bra√ßos
* Contar uma piada
* Falar sobre seu atual estado emocional
* Se apresentar
* Falar sobre a ADA
* Falar sobre o SEMEAR
* Tocar uma m√∫sica
* Soletrar uma palavra
* Falar sobre o projeto

Al√©m disso, o rob√¥, atrav√©s de m√°quinas de estado, possui a habilida de **simular sentimentos**, tendo assim um **"estado de esp√≠rito"**.

A seguir descrevemos mais detalhadamente o funcionamento do projeto.

## Funcionamento
Quando o rob√¥ √© inicializado, o mesmo fica em estado de espera, aguardando o acionamento. Quando recebe a mensagem "Ouvir", inicia a capta√ß√£o de √°udio (posteriormente ser√° utilizado um bot√£o para iniciar a capta√ß√£o). O √°udio √© armazenado em uma faixa de som (audio.wav) posteriormente enviada para `processamento_voz.py`, que utiliza a biblioteca `speech_recognition` para transformar o √°udio captado em texto. O texto ent√£o √© submetido 

![Fluxo](https://github.com/ADA-EC/SEMEADA/blob/main/readme/fluxo_robo.png)

## Executando o projeto
### Treinando o modelo

### Rodando o c√≥digo
Para rodar o projeto, executar o comando: <br>
`python Esqueleto/main.py`

## Estrutura de pastas do projeto
- üìÅ Codigo ‚û°Ô∏è cont√©m arquivos de estudo do in√≠cio do projeto
- üìÅ Esqueleto ‚û°Ô∏è cont√©m todo o c√≥digo do rob√¥
  - üêç`comandos.py` ‚û°Ô∏è mapemaneto dos comandos em n√∫meros, chamado pelo PLN
  - üêç`commSerial.py` ‚û°Ô∏è faz a comunica√ß√£o do c√≥digo python com o Arduino, chamada pela m√°quina de estados
  - üêç`main.py` ‚û°Ô∏è coordena todas as fun√ß√µes do rob√¥
    - inicializa o rob√¥
    - chama o processamento de √°udio
    - recebe o texto de volta
    - envia o texto para o processamento
    - recebe o n√∫mero do comando
    - envia para a m√°quina de estados   
  - üêç`olhos.py` ‚û°Ô∏è mapeamento dos olhos para cada estado de humor
  - üêç`PLN.py` ‚û°Ô∏è recebe o texto da *main*, faz o pr√© processamento do texto, submete ao modelo, retorna o valor do comando para a *main*
  - üêç`processamento_voz.py` ‚û°Ô∏è chamada pela *main*, capta o √°udio, transforma em texto e retorna para a *main*
  - üêç`rostos.py` ‚û°Ô∏è faz a conex√£o com o arduino (n√£o sei se est√° sendo utilizada, verificar remo√ß√£o)
  - üêç`sintese_voz.py` ‚û°Ô∏è usado para repetir o comando de voz de volta (verificar remo√ß√£o)
  - üêç`state_machine.py` ‚û°Ô∏è controla o estado de humor do rob√¥, gerencia execu√ß√£o dos comandos (recebe da *main* o comando e envia para *commSerial*)
- üìÅ Falhas_treinamento_PLN ‚û°Ô∏è cont√©m o hist√≥rico de tentativas de treinamento do modelo
- üìÅ Gravar ‚û°Ô∏è armazena o arquivo de √°udio captado
- üìÅ Maquina_Estados ‚û°Ô∏è cont√©m as imagens das m√°quinas de estados desenvolvidas no JFLAP
- üìÅ Olhos ‚û°Ô∏è cont√©m os arquivos com as imagens usada para teste das telas LCD
- üìÅ PCB ‚û°Ô∏è cont√©m o projeto das placas do rob√¥
- üìÅ Testes Arduino ‚û°Ô∏è cont√©m os arquivos comunica√ß√£o com os componentes f√≠sicos do rob√¥
- üìÅ Treinamento_PLN ‚û°Ô∏è cont√©m os arquivos de treinamento do modelo de processamento de linguagem natural

## O hardware


## Tecnologias Usadas

### Bibliotecas utilizadas
A seguir uma lista das bibliotecas utilizadas e como fazer sua instala√ß√£o, al√©m de dicas para contornar poss√≠veis erros durante a instala√ß√£o. (Todas as instala√ß√µes foram feitas utilizando o pip, n√£o usar o WSL)
- Pandas <br>
  `pip install pandas`
- SpaCy <br>
  `pip install spacy`
- Seaborn <br>
  `pip install seaborn`
- SpaCy Language Detector <br>
  `pip install spacy-langdetect`
- SpaCy pt_core_news_sm <br>
  `python -m spacy download pt_core_news_sm`
- gTTS <br>
  `pip install gTTS`
- SpeechRecognition [Caso n√£o d√™ certo, tente rodar ‚Äúpip3 install SpeechRecognition‚Äù] <br>
  `pip install SpeechRecognition`
- PlaySound [Caso n√£o d√™ certo, tente dar um downgrade para a vers√£o 1.2.2 (pip install playsound==1.2.2)] <br>
  `pip install playsound==1.2.2`
- PyDub <br>
  `pip install pydub`
- SoundDevice <br>
  `pip install sounddevice`
- SoundFile <br>
  `pip install SoundFile`
- Pyserial <br>
  `pip install pyserial`
- PyAudio <br>
  `pip install pyaudio`

### M√°quina de Estados
Para realizar o projeto, fizemos algumas m√°quinas de estados modificadas que indicam o estado do rob√¥ ap√≥s realizar os comandos.
Um exemplo disso √© a maquina de estado desenvolvida para v√°rios comandos diversos, mostrada abaixo. Nela, ap√≥s realizar um comando como dan√ßar, ele fica automaticamente no estado de "feliz".

![M√°quina de Estados - Diversos](https://github.com/ADA-EC/SEMEADA/blob/main/Maquina_Estados/Diversos.png)

Al√©m disso, nota-se na imagem que alguns comandos n√£o ser√£o obedecidos se o rob√¥ estiver em determinado estado emocional, como o comando "dan√ßar" tamb√©m, que s√≥ pode ser realizado quando este est√° "feliz", "neutro" ou "triste".

Alguns coment√°rios foram adicionados aos desenhos, para facilitar compreens√£o e auxiliar no entendimento na hora de construir o c√≥digo em Python. Um exemplo de coment√°rio pode ser visto na imagem abaixo, referente √† m√°quina de estados "Tocar m√∫sica".

![M√°quina de Estados - Tocar M√∫sica](https://github.com/ADA-EC/SEMEADA/blob/main/Maquina_Estados/Tocar_musica.png)

## Membros
- [√ârika Hort√™ncia](https://github.com/erika-hortencia)
- [Gabriela Barion Vidal](https://github.com/GabrielaVidal7)
- [Rodrigo Bragato Piva](https://github.com/Rodrigo-P)
- Marcos Almeida


## Agradecimentos
- [Victor Amaral](https://github.com/felfipe)
- [Breno Seixas]([https://github.com/TsuyoshiSonobe](https://github.com/TheGuardianB))
- [Tsuyoshi Sonobe](https://github.com/TsuyoshiSonobe)
- [Pedro Torrente](https://github.com/pdrtorrente)
- Manuella Porto
